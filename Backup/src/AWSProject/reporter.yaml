AWSTemplateFormatVersion: 2010-09-09
Description: Reporter component of the Backup Observer Solution For AWS Backup
Metadata:
  'AWS::CloudFormation::Interface':
    ParameterGroups:
      - Label:
          default: Reporter Configuration
        Parameters:
          - ReportRecipient
          - ReportGenerationHour
          - ReportGenerationMinute
          - LogsBucketName
      - Label:
          default: Binary Location
        Parameters:
          - StackBinaryURL
    ParameterLabels:
      LogsBucketName:
        default: S3 Bucket for Backup Observer Logs and Data
      ReportGenerationHour:
        default: Hour (in UTC) when report(s) are generated
      ReportGenerationMinute:
        default: Minute (in UTC) when report(s) are generated
      ReportRecipient:
        default: Recipient Email Addresses for Backup Report(s)
      StackBinaryURL:
        default: The URL for the StackBinary Zip File
Parameters:
  StackBinaryURL:
    Description: The URL for the StackBinary Zip File
    Type: String
    Default: >-
      https://awsstorageblogresources.s3.us-west-2.amazonaws.com/backupobserverblog/bos-for-aws-backup.zip
  ReportRecipient:
    Description: Comma Separated Email Id list for Report Delivery.
    Type: String
  ReportGenerationHour:
    Description: Hour in UTC when the reports need to be delivered
    Default: '23'
    Type: String
    AllowedValues:
      - '00'
      - '01'
      - '02'
      - '03'
      - '04'
      - '05'
      - '06'
      - '07'
      - 08
      - 09
      - '10'
      - '11'
      - '12'
      - '13'
      - '14'
      - '15'
      - '16'
      - '17'
      - '18'
      - '19'
      - '20'
      - '21'
      - '22'
      - '23'
  ReportGenerationMinute:
    Description: Minutes in UTC when the reports need to be delivered
    Default: '55'
    Type: String
    AllowedValues:
      - '00'
      - '05'
      - '10'
      - '15'
      - '20'
      - '25'
      - '30'
      - '35'
      - '40'
      - '45'
      - '50'
      - '55'
  LogsBucketName:
    Description: The S3 Bucket Name where the Job Logs and Reports are to be stored.
    Type: String
Resources:
  LocalCacheBucket:
    Type: 'AWS::S3::Bucket'
    DeletionPolicy: Delete
    UpdateReplacePolicy: Retain
    Properties:
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
  CleanupLocalCacheBucketOnDelete:
    Type: 'Custom::CleanupBucket'
    Properties:
      ServiceToken: !GetAtt GlobalCfnCodeReplicatorLambda.Arn
      S3BucketToCleanup: !Ref LocalCacheBucket
  GlobalCfnCodeReplicatorLambda:
    Type: 'AWS::Lambda::Function'
    Properties:
      Code:
        ZipFile: >-
          #!/usr/bin/env python

          # -*- coding: utf-8 -*-

          import json

          import boto3

          import urllib3

          import os

          import shutil

          from urllib.parse import urlparse

          physical_resource_id = 'GlobalCfnCodeReplicator'  

          def process_bucket_cleanup_request(bucket_name):
              print(f"process_bucket_cleanup_request starting for bucket_name : {bucket_name}")
              s3 = boto3.resource('s3')
              bucket_to_delete = s3.Bucket(bucket_name)
              response = bucket_to_delete.objects.all().delete()
              print(f"process_bucket_cleanup_request all object delete done. Response : {response}")

          def download_url(url, save_path):
            c = urllib3.PoolManager()
            with c.request('GET',url, preload_content=False) as resp, open(save_path, 'wb') as out_file:
                shutil.copyfileobj(resp, out_file)
            resp.release_conn()
            
          def lambda_handler(event, context):
            try:
                print(f'Handling event : {event}')
                request_type = event.get('RequestType')              
                solution_url = event['ResourceProperties'].get('SolutionURL')
                solution_bucket = event['ResourceProperties'].get('SolutionDestinationBucket')
                response_data = {
                    'RequestType': request_type,
                    'SolutionURL' : solution_url,
                    'SolutionDestinationBucket' : solution_bucket
                }
                if request_type == 'Create' or request_type == 'Update':
                    if solution_url:
                        print(f'downloading file from : {solution_url}')
                        a = urlparse(solution_url)
                        original_file_name = os.path.basename(a.path)
                        temp_file_name = '/tmp/'+original_file_name
                        download_url(solution_url,temp_file_name)
                        file_size = (os.stat(temp_file_name).st_size / 1024)
                        print(f'Downloaded report to File : {temp_file_name} , Size : {file_size}')
                        s3_client = boto3.client('s3')
                        print(f"uploading payload to : {solution_bucket} at {original_file_name}")
                        extraArgsForUpload = {'ACL':'bucket-owner-full-control', 'Tagging':'Source=StackBinaryURL'}
                        s3_client.upload_file(Filename=temp_file_name, Bucket=solution_bucket, Key=original_file_name,ExtraArgs=extraArgsForUpload)
                elif request_type == 'Delete':
                    solution_bucket = event['ResourceProperties'].get('S3BucketToCleanup')
                    if solution_bucket:
                        process_bucket_cleanup_request(solution_bucket)
                send(event, context, 'SUCCESS', response_data, physical_resource_id)
            except Exception as e:
                send(event, context, 'FAILED', response_data, physical_resource_id)
          def send(event, context, response_status, response_data,
          physical_resource_id, no_echo=False):
            http = urllib3.PoolManager()
            response_url = event['ResponseURL']
            json_response_body = json.dumps({
                'Status': response_status,
                'Reason': f'See the details in CloudWatch Log Stream: {context.log_stream_name}',
                'PhysicalResourceId': physical_resource_id,
                'StackId': event['StackId'],
                'RequestId': event['RequestId'],
                'LogicalResourceId': event['LogicalResourceId'],
                'NoEcho': no_echo,
                'Data': response_data
            }).encode('utf-8')
            headers = {
                'content-type': '',
                'content-length': str(len(json_response_body))
            }
            try:
                http.request('PUT', response_url,
                             body=json_response_body, headers=headers)
            except Exception as e:
                print(e)
      Description: Copy Solutions Binary to Local Cache Bucket
      Handler: index.lambda_handler
      Role: !GetAtt ReporterForAWSBackupRole.Arn
      Runtime: python3.7
      Timeout: 300
  GlobalBackupJobStatusEventBus:
    Type: 'AWS::Events::EventBus'
    Properties:
      Name: !Join 
        - ''
        - - GlobalBackupJobStatusEventBus-
          - !Ref 'AWS::AccountId'
  GlobalAMReportERInvokePermission:
    Type: 'AWS::Lambda::Permission'
    Properties:
      Action: 'lambda:InvokeFunction'
      FunctionName: !Ref ReporterForAWSBackupLambda
      Principal: events.amazonaws.com
      SourceArn: !Sub '${GlobalEventBridgeEventRule.Arn}'
  GlobalEventBridgeEventRule:
    Type: 'AWS::Events::Rule'
    Properties:
      Description: Send Audit Manager reports events to Lambda
      EventBusName: !Ref GlobalBackupJobStatusEventBus
      State: ENABLED
      EventPattern:
        source:
          - backupauditmanager.events
          - observer.events
      Targets:
        - Arn: !GetAtt ReporterForAWSBackupLambda.Arn
          Id: GlobalEventBridgeEvent
  GlobalBackupJobStatusEventBusPolicy:
    Type: 'AWS::Events::EventBusPolicy'
    Properties:
      EventBusName: !Ref GlobalBackupJobStatusEventBus
      StatementId: BoSGlobalEBPolicyStmt
      Statement:
        Effect: Allow
        Principal: '*'
        Action: 'events:PutEvents'
        Resource: !GetAtt GlobalBackupJobStatusEventBus.Arn
  ReporterInitializationHandler:
    Type: 'Custom::ReporterInitializationHandler'
    Properties:
      ServiceToken: !GetAtt ReporterForAWSBackupLambda.Arn
      S3Bucket: !Ref LogsBucketName
      ReportRecipient: !Ref ReportRecipient
      RefreshGluePartitions: 'true'
      CleanupGluePartitions: 'true'
      S3PrefixList: >-
        aws-backup-logs/backup_job/,aws-backup-logs/restore_job/,aws-backup-logs/copy_job/,aws-backup-logs/config_job/latest/,aws-backup-logs/backup_job_report/,aws-backup-logs/restore_job_report/,aws-backup-logs/copy_job_report/,aws-backup-logs/resource_compliance_report/,aws-backup-logs/control_compliance_report/
      S3EventHandlerLambdaArn: !GetAtt 
        - ReporterForAWSBackupLambda
        - Arn
  ReporterForAWSBackupRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: 'sts:AssumeRole'
          - Effect: Allow
            Principal:
              Service: quicksight.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      ManagedPolicyArns:
        - !Sub >-
          arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: invokeLambda
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 'lambda:InvokeFunction'
                Resource: '*'
        - PolicyName: s3Permissions
          PolicyDocument:
            Statement:
              - Effect: Allow
                Action:
                  - 'kms:GenerateDataKey'
                  - 'kms:Decrypt'
                  - 'kms:Encrypt'
                  - 's3:PutObject*'
                  - 's3:GetObject*'
                  - 's3:DeleteObject'
                  - 's3:*BucketNotification'
                  - 's3:GetBucketLocation'
                  - 's3:ListBucket'
                  - 's3:ListBucketMultipartUploads'
                  - 's3:ListMultipartUploadParts'
                  - 's3:AbortMultipartUpload'
                Resource:
                  - !Sub 'arn:${AWS::Partition}:s3:::${LogsBucketName}/*'
                  - !Sub 'arn:${AWS::Partition}:s3:::${LogsBucketName}'
                  - !Sub 'arn:${AWS::Partition}:s3:::${LocalCacheBucket}/*'
                  - !Sub 'arn:${AWS::Partition}:s3:::${LocalCacheBucket}'
        - PolicyName: logStreamPermissions
          PolicyDocument:
            Statement:
              - Effect: Allow
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource: !Sub 'arn:${AWS::Partition}:logs:*:*:*'
        - PolicyName: GlueAthenaPermissions
          PolicyDocument:
            Statement:
              - Effect: Allow
                Action:
                  - 'athena:*'
                  - 'glue:*'
                Resource: '*'
        - PolicyName: SESPermissions
          PolicyDocument:
            Statement:
              - Effect: Allow
                Action:
                  - 'SES:SendRawEmail'
                  - 'SES:SendEmail'
                  - 'SES:VerifyEmailIdentity'
                  - 'SES:GetIdentityVerificationAttributes'
                Resource: '*'
  GluePartitionAutoLoaderLambdaPermission:
    Type: 'AWS::Lambda::Permission'
    Properties:
      FunctionName: !GetAtt ReporterForAWSBackupLambda.Arn
      Action: 'lambda:InvokeFunction'
      Principal: s3.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'
      SourceArn: !Sub 'arn:${AWS::Partition}:s3:::${LogsBucketName}'
  ReporterForAWSBackupLambda:
    Type: 'AWS::Lambda::Function'
    Properties:
      Description: Function to manage AWS Backup events.
      FunctionName: ReporterForAWSBackupLambda
      Handler: lambda_handler.handler
      Role: !GetAtt 
        - ReporterForAWSBackupRole
        - Arn
      Runtime: python3.7
      MemorySize: 1024
      Timeout: 900
      Code:
        S3Bucket: !Ref LocalCacheBucket
        S3Key: bos-for-aws-backup.zip
      Environment:
        Variables:
          DailyJobReportSchedule: DailyJobReportSchedule
          S3BackupManagerLogBucket: !Ref LogsBucketName
          S3BackupManagerLogKey: aws-backup-logs
          BackupManagerStackId: !Ref 'AWS::StackId'
          GlueDatabaseName: !Ref DBForAWSBackupLogs
          GlueCacheBucket: !Ref LogsBucketName
          GlueTableNameList: !Sub >-
            ${BackupJobLogsTable},${RestoreJobLogsTable},${CopyJobLogsTable},${AWSConfigLogsTable},${BackupReportsTable},${RestoreReportsTable},${CopyReportsTable},${ControlComplianceReportsTable},${ResourceComplianceReportsTable}
          GlueTablePartitionCacheKey: GlueCache
          S3AthenaOutputURI: !Sub 's3://${LogsBucketName}/aws-backup-logs/athena_results/'
          SESEmailReportRecipientList: !Ref ReportRecipient
          S3EmailReportOutputBucket: !Ref LogsBucketName
          S3EmailReportOutputKey: aws-backup-logs/email_results/
          QUERY_BACKUP_JOB_REPORT: >-
            SELECT * FROM aws_backup_logs_db.backup_job_report where year =
            '{UtcYear}' and month = '{UtcMonth}' and day = '{UtcDay}'
          QUERY_RESTORE_JOB_REPORT: >-
            SELECT * FROM aws_backup_logs_db.restore_job_report where year =
            '{UtcYear}' and month = '{UtcMonth}' and day = '{UtcDay}'
          QUERY_COPY_JOB_REPORT: >-
            SELECT * FROM aws_backup_logs_db.copy_job_report where year =
            '{UtcYear}' and month = '{UtcMonth}' and day = '{UtcDay}'
          QUERY_DETAILED_BACKUP_REPORT: >-
            SELECT * FROM aws_backup_logs_db.aws_backup_logs_view where job_date
            = '{UtcToday}'
  DailyJobReportSchedule:
    Type: 'AWS::Events::Rule'
    Properties:
      Description: Daily Reporting Schedule
      Name: DailyJobReportSchedule
      ScheduleExpression: !Sub 'cron(${ReportGenerationMinute} ${ReportGenerationHour} * * ? *)'
      State: ENABLED
      Targets:
        - Arn: !Sub '${ReporterForAWSBackupLambda.Arn}'
          Id: DailyJobReportSchedule
  DailyJobReportSchedulePermission:
    Type: 'AWS::Lambda::Permission'
    Properties:
      Action: 'lambda:InvokeFunction'
      FunctionName: !Sub '${ReporterForAWSBackupLambda.Arn}'
      Principal: events.amazonaws.com
      SourceArn: !Sub '${DailyJobReportSchedule.Arn}'
  DBForAWSBackupLogs:
    Type: 'AWS::Glue::Database'
    Properties:
      CatalogId: !Ref 'AWS::AccountId'
      DatabaseInput:
        Description: DBForAWSBackupLogs
        Name: aws_backup_logs_db
  AthenaWorkgroup:
    Type: 'AWS::Athena::WorkGroup'
    Properties:
      Name: !Sub '${AWS::StackName}-observer-for-aws-backup-wg'
      RecursiveDeleteOption: true
      State: ENABLED
      WorkGroupConfiguration:
        ResultConfiguration:
          OutputLocation: !Sub 's3://${LogsBucketName}/aws-backup-logs/athena_results/'
  BackupReportsTable:
    Type: 'AWS::Glue::Table'
    Properties:
      CatalogId: !Ref 'AWS::AccountId'
      DatabaseName: !Ref DBForAWSBackupLogs
      TableInput:
        Name: backup_job_report
        TableType: EXTERNAL_TABLE
        PartitionKeys:
          - Name: account_partition_id
            Type: string
          - Name: region_partition_id
            Type: string
          - Name: year
            Type: string
          - Name: month
            Type: string
          - Name: day
            Type: string
          - Name: report_name
            Type: string
        StorageDescriptor:
          Location: !Sub 's3://${LogsBucketName}/aws-backup-logs/backup_job_report/csv/'
          Columns:
            - Name: report_period_start
              Type: string
            - Name: report_period_end
              Type: string
            - Name: account_id
              Type: string
            - Name: region
              Type: string
            - Name: backup_job_id
              Type: string
            - Name: job_status
              Type: string
            - Name: status_message
              Type: string
            - Name: resource_type
              Type: string
            - Name: resource_arn
              Type: string
            - Name: backup_plan_arn
              Type: string
            - Name: backup_rule_id
              Type: string
            - Name: creation_date
              Type: string
            - Name: completion_date
              Type: string
            - Name: expected_completion_date
              Type: string
            - Name: recoverypoint_arn
              Type: string
            - Name: job_run_time
              Type: string
            - Name: backup_size_in_bytes
              Type: string
            - Name: backup_vault_name
              Type: string
            - Name: backup_vault_arn
              Type: string
            - Name: iam_role_arn
              Type: string
          InputFormat: org.apache.hadoop.mapred.TextInputFormat
          OutputFormat: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
          SerdeInfo:
            Parameters:
              case.insensitive: 'true'
              field.delim: ','
              skip.header.line.count: '1'
            SerializationLibrary: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
Outputs:
  StackName:
    Value: !Ref 'AWS::StackName'
